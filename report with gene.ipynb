{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 5)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"indoc.csv\")\n",
    "data.head(10)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = data[\"Document\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['স্নাতক পাস আবুল হাশেম (৩০) ও তাঁর ভাই উচ্চমাধ্যমিক পাস সুজন হোসেন (২৩) একসময় ঢাকায় গার্মেন্টসে চাকরি করতেন',\n",
       " ' তাঁদের আরেক ভাই অষ্টম শ্রেণি পাস ফরহাদ হোসেন (২৫) আগে নোয়াখালীতে গ্রামের বাড়িতে কৃষিকাজ করতেন',\n",
       " ' এখন তিন ভাইই পরিবার নিয়ে ঢাকার উত্তরার বহুতল ভবনে বাস করেন',\n",
       " ' ভাড়া দেন ৫০ হাজার টাকা',\n",
       " ' গত শনিবার তিন ভাইয়ের দুজন সুজন ও ফরহাদকে ২০ হাজার পিছ ইয়াবাসহ উত্তরার সেই ফ্ল্যাট থেকে গ্রেপ্তার করেছে ঢাকা মহানগর গোয়েন্দা পুলিশ (ডিবি)',\n",
       " ' এই ইয়াবার আনুমানিক মূল্য ৩০ লাখ টাকা',\n",
       " ' আর তিন ভাইয়ের ফ্ল্যাট থেকে জব্দ করা হয়েছে আরও নগদ ২ লাখ ৫৭ হাজার টাকা',\n",
       " ' রোববার সুজন ও ফরহাদকে ঢাকার আদালতে হাজির করে ডিবি এক প্রতিবেদন দিয়ে বলছে, হাশেম, সুজন ও ফরহাদ তিন ভাই কয়েক বছর ধরে কক্সবাজার থেকে ইয়াবার চালান ঢাকায় এনে জমজমাট ব্যবসা করছেন',\n",
       " ' তাঁদের সঙ্গে কারা জড়িত, তা খুঁজে বের করতে দুই ভাইকে তিন দিন জিজ্ঞাসাবাদের অনুমতি দিয়েছেন আদালত',\n",
       " ' তিনজনের বাবা ছিলেন হকারমাদক ব্যবসার অভিযোগ থাকা এই তিনজনের বাবার নাম বিল্লাল হোসেন',\n",
       " ' তাঁর গ্রামের বাড়ি নোয়াখালী',\n",
       " ' অনেক আগে থেকে তিনি ঢাকায় থাকেন',\n",
       " ' রাজধানীর বিমানবন্দর এলাকায় ফুটপাতে হকারি করতেন',\n",
       " ' পরিবার নিয়ে থাকতেন আশকোনাতে',\n",
       " ' বিল্লাল হোসেন এখন এই তিন ছেলের সঙ্গে উত্তরার ছেলেদের ফ্ল্যাটে থাকেন',\n",
       " ' ২০ হাজার পিছ ইয়াবাসহ যখন তাঁর দুই ছেলেকে গ্রেপ্তার করা হয়, তখন বিল্লাল হোসেন ওই বাসাতেই ছিলেন',\n",
       " ' দুই ভাইকে গ্রেপ্তার অভিযানে অংশ নেওয়া ঢাকা মহানগর গোয়েন্দা পুলিশের সহকারী কমিশনার (এসি) মো মাহবুবুল আলম প্রথম আলোকে বলেন, বিল্লাল হোসেনের ছেলে সুজন এর আগেও মাদকসহ গ্রেপ্তার হয়েছিল',\n",
       " ' এই তিন ভাই বেশ কয়েক বছর ধরে মাদক ব্যবসা করে আসছেন',\n",
       " ' তিন ভাইয়ের বাসায় ইয়াবা ব্যবসাপুলিশ বলছে, এই তিন ভাইয়ের মধ্যে নেতা হলেন আবুল হাশেম',\n",
       " ' কক্সবাজারের বড় বড় মাদক ব্যবসায়ীর সঙ্গে যোগাযোগ রেখে ইয়াবার চালান আনেন ঢাকায়',\n",
       " ' এ কাজে তাঁরা নোয়াখালীকে ট্রানজিট হিসেবে ব্যবহার করেন',\n",
       " ' আর তাঁর ভাই সুজন ও ফরহাদ ঢাকার পাইকারি ও খুচরা ব্যবসায়ীদের কাছে ইয়াবা বিক্রি করেন',\n",
       " ' মামলার তদন্ত কর্মকর্তা ডিবির পরিদর্শক মুক্তার হোসেন প্রথম আলোকে বলেন, উত্তরার ওই ফ্ল্যাটে মাদক রাখতেন তিন ভাই',\n",
       " ' তাঁদের ফ্ল্যাটে মাদক ব্যবসায়ীদের আনাগোনা ছিল',\n",
       " ' গ্রেপ্তার অভিযানে অংশ নেওয়া একাধিক ডিবি কর্মকর্তা জানান, শনিবার নোয়াখালী থেকে ইয়াবার চালান বাসে করে আনেন সুজন ও ফরহাদ',\n",
       " ' তবে তাঁদের ভাই আবুল হাশেম নোয়াখালীতেই থেকে যান',\n",
       " ' ভাইদের গ্রেপ্তার হওয়ার খবর শোনার পর হাশেম গা–ঢাকা দিয়েছেন',\n",
       " ' ডিবির সহকারী কমিশনার মাহবুবুল আলম প্রথম আলোকে বলেন, ভাইদের গ্রেপ্তার খবর শোনার পর থেকে হাশেমের মোবাইল ফোন বন্ধ পাওয়া যাচ্ছে',\n",
       " ' তবে হাশেমকে যেকোনো সময় গ্রেপ্তার করা হবে',\n",
       " ' মাহবুবুল আলম আরও বলেন, সুজন ও ফরহাদদের জিজ্ঞাসা করে জানতে পেরেছেন, মাদক ব্যবসা করে অনেক টাকা বানিয়েছেন',\n",
       " ' এই ডিবি কর্মকর্তা মনে করছেন, হাশেমদের পুরো পরিবার মাদক ব্যবসার সঙ্গে জড়িত',\n",
       " ' ']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cl = [xs.replace('ইহাতে মন্তব্য প্রদান বন্ধ রয়েছে                                |    ', '') for xs in docs]\n",
    "cl2 = [xs.replace('\\xa0', '').replace('\\u200c', '') for xs in cl]\n",
    "cl3 = [xs.replace('?', u'।').replace('!', u'।').replace(';', u'।') for xs in cl]\n",
    "\n",
    "sentTok =[]\n",
    "wordTok = []\n",
    "for doc in cl3:\n",
    "    sentTok.append(doc.split('।'))\n",
    "sentTok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ঢাকার', 'কামরাঙ্গীরচরের', 'নবাবচরে', 'বুড়িগঙ্গা', 'নদী', 'দখল', 'স্থায়ী', 'রূপ', 'নিচ্ছে', 'নদীর', 'সীমানা', 'নির্ধারণ', 'বিষয়ে', 'জেলা', 'প্রশাসনের', 'প্রতিবেদনের', 'কারণে', 'অবস্থার', 'সৃষ্টি', 'রয়েছে', 'প্রভাবশালী', 'ব্যক্তিদের', 'চাপ', 'অভ্যন্তরীণ', 'নৌপরিবহন', 'কর্তৃপক্ষের', 'বিআইডব্লিউটিএ', 'উদ্যোগের', 'অভাব', 'বিআইডব্লিউটিএ', 'জেলা', 'প্রশাসন', 'সূত্রে', 'নৌপরিবহনমন্ত্রী', 'শাজাহান', 'খান', 'গত', 'বছরের', 'এপ্রিলে', 'বুড়িগঙ্গার', 'কামরাঙ্গীরচর', 'এলাকা', 'পরিদর্শন', 'সময়', 'নদীর', 'জায়গায়', 'অবৈধ', 'স্থাপনা', 'গড়ে', 'উঠেছে', 'সেগুলো', 'ভাঙার', 'ঘোষণা', 'এরপর', 'জুলাই', 'বিআইডব্লিউটিএ', 'অভিযান', 'চালিয়ে', 'তিনটি', 'স্থাপনার', 'বাইরের', 'দেয়ালের', 'সামান্য', 'অংশ', 'ভেঙে', 'দেয়', 'সাংসদ', 'হাজি', 'সেলিমের', 'মালিকানাধীন', 'স্থাপনার', 'সীমানাদেয়াল', 'ভাঙা', 'এরপরই', 'নবাবচরে', 'নদীতীরের', 'ভবনমালিকেরা', 'জেলা', 'প্রশাসনের', 'সীমানা', 'নির্ধারণের', 'আবেদন', 'জানালে', 'কমিটি', 'কমিটি', 'সিএস', 'ক্যাডেস্টাইল', 'সার্ভে', 'আরএস', 'রিভাইস', 'সার্ভে', 'রেকর্ড', 'অনুযায়ী', 'নদীর', 'সীমানা', 'নির্ধারণের', 'প্রস্তাবসহ', 'প্রতিবেদন', 'দাখিল', 'এরপরই', 'অভিযান', 'বন্ধ', 'হয়ে', 'যায়', 'বিআইডব্লিউটিএর', 'চেয়ারম্যান', 'মোজাম্মেল', 'হোসেন', 'আলোকে', 'জেলা', 'প্রশাসন', 'বর্তমানে', 'সিএস', 'আরএস', 'অনুসারে', 'জরিপ', 'সীমানা', 'খুঁটি', 'বসাতে', 'চাইছে', 'চায়', 'নদীর', 'ওপরে', 'নিচে', 'খুঁটি', 'স্থাপন', 'নদীর', 'স্বার্থ', 'রক্ষা', 'পাবে', 'বিশেষজ্ঞরা', 'বলছেন', 'চারটি', 'নদীর', 'বিষয়ে', 'সালে', 'হাইকোর্টের', 'আদেশে', 'সিএস', 'আরএসের', 'কথা', 'হয়েছে', 'মূলত', 'নদীর', 'অবস্থান', 'নির্ণয়ের', 'সীমানা', 'চিহ্নিত', 'নদীর', 'আকার', 'অনুযায়ী', 'আদেশে', 'নদীর', 'সীমানা', 'নির্ধারণে', 'সবকিছু', 'বিবেচনায়', 'নেওয়ার', 'নির্দেশনা', 'রয়েছে', 'জেলা', 'প্রশাসন', 'প্রতিবেদনে', 'সিএস', 'আরএস', 'মানচিত্র', 'অনুসরণে', 'জরিপ', 'চাইছে', 'এভাবে', 'বর্তমানে', 'স্থাপিত', 'খুঁটিগুলো', 'ফুট', 'নদীর', 'নামিয়ে', 'চাইলে', 'সদ্য', 'যোগ', 'জেলা', 'প্রশাসক', 'আবু', 'সালে', 'মো', 'ফেরদৌস', 'খান', 'বিষয়টি', 'খতিয়ে', 'দেখবেন', 'জেলা', 'প্রশাসন', 'অবশ্যই', 'নদী', 'রক্ষার', 'স্বার্থে', 'এদিকে', 'নবাবচরে', 'নদীতীরের', 'স্থাপনার', 'মালিকেরা', 'আলোকে', 'নৌমন্ত্রী', 'খাদ্যমন্ত্রীকে', 'বোঝাতে', 'সক্ষম', 'হওয়ায়', 'জুলাইয়ের', 'উচ্ছেদ', 'অভিযান', 'বন্ধ', 'বিষয়ে', 'চাইলে', 'নৌমন্ত্রী', 'শাজাহান', 'খান', 'আলোকে', 'বাড়ির', 'মালিকেরা', 'খাদ্যমন্ত্রী', 'মাপজোখ', 'বলায়', 'উচ্ছেদ', 'বন্ধ', 'খাদ্যমন্ত্রী', 'কামরুল', 'ইসলাম', '‘বাড়ির', 'মালিকেরা', 'অভিযোগ', 'ঠিকভাবে', 'মাপজোখ', 'নদীর', 'সীমানা', 'নির্ধারণ', 'হয়েছে', 'অভিযোগের', 'ভিত্তিতেই', 'নৌমন্ত্রীর', 'আলোচনা', 'করেছিলাম', 'ভাঙতে', 'চায়', 'ভেঙে', 'দিক', '’', 'স্থাপনা', 'মেরামত', 'বাড়ানোর', 'উৎসব', 'নবাবচর', 'এলাকাটি', 'বুড়িগঙ্গা', 'নদীর', 'ঢাকা', 'প্রান্তে', 'গত', 'বৃহস্পতিবার', 'সকালে', 'এখানকার', 'গুদারাঘাট-আশ্রাফাবাদ', 'এলাকায়', 'যায়', 'নদীতীরে', 'অনেকগুলো', 'পাকা', 'ভবন', 'ভবন', 'তৈরির', 'প্রচুর', 'ইট', 'বালু', 'রড', 'সিমেন্ট', 'জড়ো', 'হয়েছে', 'তৈরি', 'বাড়িগুলোর', 'কোনোটায়', 'সদ্য', 'রং', 'লাগানো', 'হয়েছে', '‘ভাড়া', 'হবে’', 'সাইনবোর্ডও', 'ঝুলছে', 'এগুলোর', 'নদীর', 'সম্পূর্ণ', 'আংশিক', 'জায়গায়', 'অবস্থিত', 'এলাকাবাসী', 'জানান', 'গত', 'জুলাইয়ে', 'উচ্ছেদ', 'অভিযান', 'চালানোর', 'বেশির', 'ভাগ', 'বাড়ির', 'লোকজন', 'সরে', 'গিয়েছিলেন', 'মাসখানেক', 'সবাই', 'এসেছেন', 'ভেঙে', 'স্থাপনা', 'মেরামত', 'আগের', 'স্থাপনার', 'অংশও', 'যুক্ত', 'এলাকা', 'ঘুরে', 'যায়', 'নদীর', 'অস্থায়ী', 'সীমানা', 'খুঁটির', 'ভেতরের', 'জায়গায়', 'স্থাপনা', 'রয়েছে', 'ঢাকা-', 'আসনের', 'সাংসদ', 'হাজি', 'মো', 'সেলিমের', 'মালিকানাধীন', 'মদীনা', 'ট্রেডিংয়ের', 'রড-সিমেন্ট', 'বিক্রির', 'একতলা', 'পাকা', 'স্থাপনা', 'স', 'মিল', 'পাশের', 'দোতলা', 'ভবনের', 'মালিক', 'মো', 'সিরাজ', 'অংশ', 'যুক্ত', 'মো', 'সিরাজ', 'আলোকে', 'নদীর', 'এক', 'ইঞ্চি', 'জায়গাও', 'নেননি', 'গুদারাঘাট', 'সড়কের', 'পাশেই', 'ছয়তলা', 'ভবন', 'নির্মাণ', 'হয়েছে', 'উচ্ছেদ', 'অভিযানের', 'ভবনটি', 'তালাবন্ধ', 'মাসখানেক', 'ভবনটি', 'সংস্কার', 'রং', 'লাগানো', 'নিচতলায়', 'কুসুম', 'কনফেকশনারি', 'নামে', 'দোকান', 'দোকানি', 'লাখ', 'টাকা', 'আগাম', 'দিয়ে', 'ভাড়া', 'নিয়েছেন', 'পাশেই', 'নদীতীরে', 'কেরামত', 'আলী', 'নামের', 'এক', 'ব্যক্তির', 'আংশিক', 'ভেঙে', 'দোতলা', 'ভবন', 'সীমানাদেয়াল', 'মেরামত', 'অপর', 'দোতলা', 'একতলা', 'ভবনে', 'নকিয়া', 'ফ্রুট', 'ইন্ডাস্ট্রিজ', 'বেল্ট', 'সু-প্লাস্টিক', 'অ্যান্ড', 'রাবার', 'ফ্যাক্টরি', 'দক্ষিণ', 'মুন্সিহাটি', 'নদীর', 'পাড়ে', 'আরেকটি', 'দোতলা', 'ভবনে', 'দোকানপাট', 'পাশেই', 'পারফেক্ট', 'ডেলটা', 'ফ্যাক্টরি', 'নামে', 'প্লাস্টিক', 'ইনসাফ', 'ফ্রুটস', 'এগ্রো', 'বেজ', 'ইন্ডাস্ট্রিজের', 'কারখানা', 'ছাড়া', 'নদীতীরে', 'রয়েছে', 'স', 'মিল', 'মিষ্টির', 'দোকান', 'ডেইরি', 'ফার্ম', 'গুদামসহ', 'অবৈধ', 'স্থাপনা', 'পক্ষ', 'ভবনমালিক', 'মো', 'সিরাজ', 'মো', 'মাহবুব', 'আলোকে', 'বছর', 'এসব', 'জায়গার', 'খাজনা', 'দিয়ে', 'আসছেন', 'তাঁরাই', 'জায়গার', 'প্রকৃত', 'মালিক', 'আইনজীবী', 'মনজিল', 'মোরসেদ', 'বিষয়ে', 'আলোকে', 'অর্থনৈতিক', 'স্বার্থেই', 'জেলা', 'প্রশাসন', 'ভবনমালিকদের', 'পক্ষ', 'প্রতিবেদন', 'তৈরি', 'প্রতিবেদন', 'থাকলে', 'নদী', 'বিষয়ে', 'মূল', 'রায়', 'অকার্যকর', 'হয়ে', 'অনুসন্ধানে', 'যায়', 'নবাবচরে', 'নদীতীরের', 'আধা', 'কিলোমিটার', 'এলাকাজুড়ে', 'নির্মিত', 'স্থাপনাগুলোর', 'নকশার', 'অনুমোদন', 'হয়নি', 'কামরাঙ্গীরচরের', 'রসুলপুর', 'বসিলা', 'ছয়', 'কিলোমিটার', 'এলাকায়', 'নদীতীরে', 'শত', 'শত', 'অবৈধ', 'স্থাপনা', 'রয়েছে', 'একইভাবে', 'তুরাগ', 'বালু', 'শীতলক্ষ্যার', 'জায়গা', 'বেদখলে', 'রয়েছে']\n",
      "1200\n",
      "334901\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import re\n",
    "pnList = ['.', ',', ':', '(', ')', '[', ']', '{', '}', '`', '*', '&', '‘', '’', '–']\n",
    "cl4 = [xs.replace(u'।',\" \") for xs in cl3]\n",
    "\n",
    "cl5=[[] for x in range(len(cl4))]\n",
    "for i in range(len(cl4)):\n",
    "#     cl5[i] = cl4[i].replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").replace(\"+\",\"\").replace(\")\",\"\")\n",
    "    cl5[i] = re.sub(\"[০১২৩৪৫৬৭৮৯]\",'',cl4[i])\n",
    "    cl5[i] = re.sub(\"[,./<>)(}{_*&^%$#@~`]\",'',cl5[i])\n",
    "\n",
    "for doc in cl5:\n",
    "    wordTok.append(doc.split())\n",
    "\n",
    "\n",
    "#remove stopword\n",
    "stRem = [[] for i in range(len(wordTok))]\n",
    "\n",
    "def remStWords(punctuF):\n",
    "    stWord = open(\"./stopwords-bn.txt\", encoding='utf8')\n",
    "    stWordFile = [i.rstrip() for i in stWord]\n",
    "    filtStWord = [w for w in punctuF if w not in stWordFile]\n",
    "\n",
    "    return filtStWord\n",
    "for i in range(len(wordTok)):\n",
    "    stRem[i] = remStWords(wordTok[i])\n",
    "    \n",
    "\n",
    "print(stRem[1])\n",
    "print(len(stRem))\n",
    "allWord = []\n",
    "for i in range(len(stRem)):\n",
    "    allWord+=stRem[i]\n",
    " \n",
    "\n",
    "\n",
    "print(len(allWord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "inp = open('F:\\dataP\\\\tfidfSorted','rb')\n",
    "\n",
    "tfidfSorted = pk.load(inp)\n",
    "inp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "#Import model for NB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "import itertools\n",
    "tfIdfSorted = dict(itertools.islice(tfidfSorted.items(),6000))\n",
    "\n",
    "# create classifier object gor model\n",
    "model=GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = pd.read_csv(\"F:\\\\dataP\\\\keyF6k.csv\")\n",
    "key.head(5)\n",
    "len(stRem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyF = list(key['key'])\n",
    "tfIdfFl = [[] for i in range(len(stRem))] \n",
    "for i in range(len(stRem)):\n",
    "    for word in keyF:\n",
    "        if word in stRem[i]:\n",
    "            tfIdfFl[i].append(tfIdfSorted[word])\n",
    "        else:\n",
    "            tfIdfFl[i].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3043"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfIdfFl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "dataX = tfIdfFl\n",
    "dataY = data['class']\n",
    "print(len(dataX))\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(dataX, dataY, test_size = 0.20, random_state = 0,stratify=dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX = dataX[:960]\n",
    "# trainY = dataY[:960]\n",
    "\n",
    "# testX = dataX[460:]\n",
    "# testY = dataY[460:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy using NB : 0.9947916666666666\n",
      "\n",
      "Test Accuracy using NB : 0.8541666666666666\n",
      "\n",
      "Confusion matrix:\n",
      " [[156   1   0   3   0   0]\n",
      " [  0 160   0   0   0   0]\n",
      " [  0   0 160   0   0   0]\n",
      " [  1   0   0 159   0   0]\n",
      " [  0   0   0   0 160   0]\n",
      " [  0   0   0   0   0 160]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           ['']       0.99      0.97      0.98       160\n",
      "['আন্তর্জাতিক']       0.99      1.00      1.00       160\n",
      "       ['খেলা']       1.00      1.00      1.00       160\n",
      "  ['দূর পরবাস']       0.98      0.99      0.99       160\n",
      "   ['বাংলাদেশ']       1.00      1.00      1.00       160\n",
      "     ['বিনোদন']       1.00      1.00      1.00       160\n",
      "\n",
      "       accuracy                           0.99       960\n",
      "      macro avg       0.99      0.99      0.99       960\n",
      "   weighted avg       0.99      0.99      0.99       960\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[36  0  0  3  1  0]\n",
      " [12 25  0  1  1  1]\n",
      " [ 1  0 39  0  0  0]\n",
      " [ 4  0  0 36  0  0]\n",
      " [ 3  0  0  6 31  0]\n",
      " [ 2  0  0  0  0 38]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           ['']       0.62      0.90      0.73        40\n",
      "['আন্তর্জাতিক']       1.00      0.62      0.77        40\n",
      "       ['খেলা']       1.00      0.97      0.99        40\n",
      "  ['দূর পরবাস']       0.78      0.90      0.84        40\n",
      "   ['বাংলাদেশ']       0.94      0.78      0.85        40\n",
      "     ['বিনোদন']       0.97      0.95      0.96        40\n",
      "\n",
      "       accuracy                           0.85       240\n",
      "      macro avg       0.89      0.85      0.86       240\n",
      "   weighted avg       0.89      0.85      0.86       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Import model for NB\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "# create classifier object gor model\n",
    "model=GaussianNB()\n",
    "\n",
    "# train the model with fit function\n",
    "model.fit(trainX, trainY)\n",
    "   \n",
    "# make predictions on training data\n",
    "predictions_train = model.predict(trainX)\n",
    "print('\\nTraining Accuracy using NB :',accuracy_score(trainY, predictions_train))\n",
    "\n",
    "# make predictions on test data\n",
    "predictions_test = model.predict(testX)\n",
    "print('\\nTest Accuracy using NB :',accuracy_score(testY, predictions_test))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print('\\nConfusion matrix:\\n',confusion_matrix(trainY,predictions_train))\n",
    "print(classification_report(trainY,predictions_train))  \n",
    "\n",
    "print('\\nConfusion matrix:\\n',confusion_matrix(testY,predictions_test))\n",
    "print(classification_report(testY,predictions_test)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy using NB : 1.0\n",
      "\n",
      "Test Accuracy using NB : 0.8208333333333333\n",
      "\n",
      "Confusion matrix:\n",
      " [[160   0   0   0   0   0]\n",
      " [  0 160   0   0   0   0]\n",
      " [  0   0 160   0   0   0]\n",
      " [  0   0   0 160   0   0]\n",
      " [  0   0   0   0 160   0]\n",
      " [  0   0   0   0   0 160]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           ['']       1.00      1.00      1.00       160\n",
      "['আন্তর্জাতিক']       1.00      1.00      1.00       160\n",
      "       ['খেলা']       1.00      1.00      1.00       160\n",
      "  ['দূর পরবাস']       1.00      1.00      1.00       160\n",
      "   ['বাংলাদেশ']       1.00      1.00      1.00       160\n",
      "     ['বিনোদন']       1.00      1.00      1.00       160\n",
      "\n",
      "       accuracy                           1.00       960\n",
      "      macro avg       1.00      1.00      1.00       960\n",
      "   weighted avg       1.00      1.00      1.00       960\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[28  5  1  3  2  1]\n",
      " [ 3 31  1  3  2  0]\n",
      " [ 1  0 38  0  0  1]\n",
      " [ 5  0  0 33  0  2]\n",
      " [ 5  0  1  2 32  0]\n",
      " [ 1  2  0  2  0 35]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           ['']       0.65      0.70      0.67        40\n",
      "['আন্তর্জাতিক']       0.82      0.78      0.79        40\n",
      "       ['খেলা']       0.93      0.95      0.94        40\n",
      "  ['দূর পরবাস']       0.77      0.82      0.80        40\n",
      "   ['বাংলাদেশ']       0.89      0.80      0.84        40\n",
      "     ['বিনোদন']       0.90      0.88      0.89        40\n",
      "\n",
      "       accuracy                           0.82       240\n",
      "      macro avg       0.82      0.82      0.82       240\n",
      "   weighted avg       0.82      0.82      0.82       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Import model for NB\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "# create classifier object gor model\n",
    "model=svm.SVC(kernel='linear', C=.5)\n",
    "\n",
    "# train the model with fit function\n",
    "model.fit(trainX, trainY)\n",
    "   \n",
    "# make predictions on training data\n",
    "predictions_train = model.predict(trainX)\n",
    "print('\\nTraining Accuracy using NB :',accuracy_score(trainY, predictions_train))\n",
    "\n",
    "# make predictions on test data\n",
    "predictions_test = model.predict(testX)\n",
    "print('\\nTest Accuracy using NB :',accuracy_score(testY, predictions_test))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print('\\nConfusion matrix:\\n',confusion_matrix(trainY,predictions_train))\n",
    "print(classification_report(trainY,predictions_train))  \n",
    "\n",
    "print('\\nConfusion matrix:\\n',confusion_matrix(testY,predictions_test))\n",
    "print(classification_report(testY,predictions_test)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy using DT : 1.000000\n",
      "\n",
      "Test Accuracy using DT : 0.7166666666666667\n",
      "\n",
      "Confusion matrix:\n",
      " [[160   0   0   0   0   0]\n",
      " [  0 160   0   0   0   0]\n",
      " [  0   0 160   0   0   0]\n",
      " [  0   0   0 160   0   0]\n",
      " [  0   0   0   0 160   0]\n",
      " [  0   0   0   0   0 160]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           ['']       1.00      1.00      1.00       160\n",
      "['আন্তর্জাতিক']       1.00      1.00      1.00       160\n",
      "       ['খেলা']       1.00      1.00      1.00       160\n",
      "  ['দূর পরবাস']       1.00      1.00      1.00       160\n",
      "   ['বাংলাদেশ']       1.00      1.00      1.00       160\n",
      "     ['বিনোদন']       1.00      1.00      1.00       160\n",
      "\n",
      "       accuracy                           1.00       960\n",
      "      macro avg       1.00      1.00      1.00       960\n",
      "   weighted avg       1.00      1.00      1.00       960\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[29  3  1  2  3  2]\n",
      " [ 3 23  5  2  5  2]\n",
      " [ 4  1 29  1  3  2]\n",
      " [ 2  4  2 30  2  0]\n",
      " [ 2  2  2  1 33  0]\n",
      " [ 2  5  0  1  4 28]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           ['']       0.69      0.72      0.71        40\n",
      "['আন্তর্জাতিক']       0.61      0.57      0.59        40\n",
      "       ['খেলা']       0.74      0.72      0.73        40\n",
      "  ['দূর পরবাস']       0.81      0.75      0.78        40\n",
      "   ['বাংলাদেশ']       0.66      0.82      0.73        40\n",
      "     ['বিনোদন']       0.82      0.70      0.76        40\n",
      "\n",
      "       accuracy                           0.72       240\n",
      "      macro avg       0.72      0.72      0.72       240\n",
      "   weighted avg       0.72      0.72      0.72       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#Import model for NB\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "# create classifier object gor model\n",
    "model=DecisionTreeClassifier()\n",
    "\n",
    "# train the model with fit function\n",
    "model.fit(trainX, trainY)\n",
    "   \n",
    "# make predictions on training data\n",
    "predictions_train = model.predict(trainX)\n",
    "print('\\nTraining Accuracy using DT : %f'%accuracy_score(trainY, predictions_train))\n",
    "\n",
    "# make predictions on test data\n",
    "predictions_test = model.predict(testX)\n",
    "print('\\nTest Accuracy using DT :',accuracy_score(testY, predictions_test))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print('\\nConfusion matrix:\\n',confusion_matrix(trainY,predictions_train))\n",
    "print(classification_report(trainY,predictions_train))  \n",
    "\n",
    "print('\\nConfusion matrix:\\n',confusion_matrix(testY,predictions_test))\n",
    "print(classification_report(testY,predictions_test)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
